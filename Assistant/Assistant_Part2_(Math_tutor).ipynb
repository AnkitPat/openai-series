{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9af9925b-503d-4a27-96a7-eb8a19d03895",
      "metadata": {
        "id": "9af9925b-503d-4a27-96a7-eb8a19d03895"
      },
      "source": [
        "# OpenAI Assistants APIs\n",
        "\n",
        "The Assistants' API lets you create AI assistants in your applications. These assistants follow instruction. They use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever, to query against two pdf documents we will upload.\n",
        "\n",
        "The architecture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes asynchronously, adding and reading messages to the Threads.\n",
        "\n",
        "For integrating the Assistants API:\n",
        "\n",
        "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
        "\n",
        "2. Initiate a Thread for each user conversation.\n",
        "    \n",
        "3. Add user queries as Messages to the Thread.\n",
        "\n",
        "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
        "\n",
        "Below we follow those steps to demonstrate how to integrate Assistants API, using Retrieval tool, to a) upload a couple of pdf documents and b) use Assistant to query the contents of the document. Consider this as a mini Retrieval Augmented Generation (RAG).\n",
        "\n",
        "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
        "\n",
        "<img src=\"./images/assistant_ai_tools_retriever.png\">\n",
        "\n",
        "**Note**: Much of the code and diagrams are inspired from  Randy Michak of [Empowerment AI](https://www.youtube.com/watch?v=yzNG3NnF0YE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be6985d-73b5-451f-8553-35b5c7722aa1",
      "metadata": {
        "id": "9be6985d-73b5-451f-8553-35b5c7722aa1"
      },
      "source": [
        "## How to use Assistant API using Tools: Retriever using multiple documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ikFvuGFdXU9x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikFvuGFdXU9x",
        "outputId": "d0c839e4-f339-407d-f905-b640a5e32d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.46.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aee73f00-842b-4f78-9329-37cac4ce7649",
      "metadata": {
        "id": "aee73f00-842b-4f78-9329-37cac4ce7649"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import os\n",
        "import time\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from typing import List\n",
        "from assistant_utils import print_thread_messages, upload_files, \\\n",
        "                            loop_until_completed, create_assistant_run"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31b3da3-749a-493f-a096-d421bb8d5a3a",
      "metadata": {
        "id": "d31b3da3-749a-493f-a096-d421bb8d5a3a"
      },
      "source": [
        "Load our *.env* file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints.\n",
        "\n",
        "**Note**: Assistant API calling for Anyscale Endpoints (which serves only OS models) is not yet aviable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1f59de24-3cfd-49c7-a12d-6a63adc42c14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f59de24-3cfd-49c7-a12d-6a63adc42c14",
        "outputId": "d85500c8-36cc-4a30-b036-10d15a9cb86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
        "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", \"\")\n",
        "MODEL = os.getenv(\"MODEL\")\n",
        "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211325a3-e2d2-47ec-9c4f-8edde762c816",
      "metadata": {
        "id": "211325a3-e2d2-47ec-9c4f-8edde762c816"
      },
      "source": [
        "Upload two pdfs. OpenAI allows up twenty files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b5290173-5866-495a-9817-2aaeb46dd001",
      "metadata": {
        "id": "b5290173-5866-495a-9817-2aaeb46dd001"
      },
      "outputs": [],
      "source": [
        "DOCS_TO_LOAD = [\"docs/llm_survey_halluciantions.pdf\",\n",
        "                \"docs/1001-math-problems-2nd.pdf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "23640811-8909-471c-a6ce-2bc7be35f381",
      "metadata": {
        "id": "23640811-8909-471c-a6ce-2bc7be35f381"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = openai.api_key,\n",
        "    base_url = openai.api_base\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbca03f5-0fca-4d7d-b2b5-89594b145fa0",
      "metadata": {
        "id": "dbca03f5-0fca-4d7d-b2b5-89594b145fa0"
      },
      "source": [
        "### Step 1: Create our knowledgebase\n",
        "This entails uploading your pdfs as your knowledgebase for the retrievers to use. Once you upload a file, the Assistant from OpenAI will break it into smaller chuncks, sort and save these chuncks, index and store the embeddings as vectors.\n",
        "\n",
        "The retrievers use your query to retrieve the best semantic matches on vectors in the knowledgebase, and then feed the LLM, along with the original query, to generate the consolidated and comprehesive answer, similarly to how a large-scale RAG retriever operates.\n",
        "\n",
        "Upload the data files from your storage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ed87a4-be83-4cbc-b4a1-7e494d7240c1",
      "metadata": {
        "id": "b9ed87a4-be83-4cbc-b4a1-7e494d7240c1"
      },
      "source": [
        "### Step 2: Create an Assistant\n",
        "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, and file ids to use for its knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c992db14-d667-4146-96cd-a021f285272c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c992db14-d667-4146-96cd-a021f285272c",
        "outputId": "16f99b0b-d320-4e2d-f9d1-b39e52373d7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Assistant(id='asst_XrHEBSlOf5BFxVCkibWbvu56', created_at=1726655410, description=None, instructions='You are a personal math tutor. Write and run code to answer math questions.', metadata={}, model='gpt-4-1106-preview', name='Math Tutor', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Math Tutor\",\n",
        "  instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        "  model=MODEL,\n",
        ")\n",
        "\n",
        "assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f61be56-7e39-46db-a95e-e63f9e17115e",
      "metadata": {
        "id": "9f61be56-7e39-46db-a95e-e63f9e17115e"
      },
      "source": [
        "### Step 3: Create a thread\n",
        "As the diagram above shows, the Thread is the object with which the AI Assistant runs will interact with, by fetching messages and putting messages to it. Think of a thread as a \"conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context window.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0d7d7a40-4845-4940-9732-be5a163cdc0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d7d7a40-4845-4940-9732-be5a163cdc0f",
        "outputId": "c54526cd-6590-4ac9-d9a2-cd92d22824a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Thread(id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', created_at=1726655410, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thread = client.beta.threads.create()\n",
        "thread"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577bf171-aca4-4d7d-9424-e87e97a88eff",
      "metadata": {
        "id": "577bf171-aca4-4d7d-9424-e87e97a88eff"
      },
      "source": [
        "### Step 4: Add your message query to the thread for the Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bc8a1215-c72e-4aa9-bada-f0ac6228b733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8a1215-c72e-4aa9-bada-f0ac6228b733",
        "outputId": "dcd677b3-0ec0-4c59-c3d5-d6ce82e3c837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'msg_7TwBVbZhqeiNdWljCMmjWbVK',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1726655410,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_DEB9cE0RjOR3ExXXJNwZeEK8'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
        ")\n",
        "message.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b779a37b-f530-4207-83ba-e990bba3f32d",
      "metadata": {
        "id": "b779a37b-f530-4207-83ba-e990bba3f32d"
      },
      "source": [
        "### Step 5: Create a Run for the Assistant\n",
        "A Run is an invocation of an Assistant on a Thread. The Assistant uses its configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
        "\n",
        "Note that Assistance will run asychronously: the run has the following\n",
        "lifecycle and states: [*expired, completed, failed, cancelled*]. Run objects can have multiple statuses.\n",
        "\n",
        "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f2d296c8-4ba4-4233-8e82-772762298a28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2d296c8-4ba4-4233-8e82-772762298a28",
        "outputId": "ec8aa13c-5ee7-4617-da0c-0872adcb37e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"run_yhPlfNfrSXZ06TZxAMI2KVso\",\n",
            "  \"assistant_id\": \"asst_XrHEBSlOf5BFxVCkibWbvu56\",\n",
            "  \"cancelled_at\": null,\n",
            "  \"completed_at\": null,\n",
            "  \"created_at\": 1726655410,\n",
            "  \"expires_at\": 1726656010,\n",
            "  \"failed_at\": null,\n",
            "  \"incomplete_details\": null,\n",
            "  \"instructions\": \"Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n\",\n",
            "  \"last_error\": null,\n",
            "  \"max_completion_tokens\": null,\n",
            "  \"max_prompt_tokens\": null,\n",
            "  \"metadata\": {},\n",
            "  \"model\": \"gpt-4-1106-preview\",\n",
            "  \"object\": \"thread.run\",\n",
            "  \"parallel_tool_calls\": true,\n",
            "  \"required_action\": null,\n",
            "  \"response_format\": \"auto\",\n",
            "  \"started_at\": null,\n",
            "  \"status\": \"queued\",\n",
            "  \"thread_id\": \"thread_DEB9cE0RjOR3ExXXJNwZeEK8\",\n",
            "  \"tool_choice\": \"auto\",\n",
            "  \"tools\": [\n",
            "    {\n",
            "      \"type\": \"code_interpreter\"\n",
            "    }\n",
            "  ],\n",
            "  \"truncation_strategy\": {\n",
            "    \"type\": \"auto\",\n",
            "    \"last_messages\": null\n",
            "  },\n",
            "  \"usage\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_p\": 1.0,\n",
            "  \"tool_resources\": {}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.\n",
        "    Do not provide an answer to the question if the information was not retrieved from\n",
        "    the knowledge base.\n",
        "\"\"\"\n",
        "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
        "print(run.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce860b7-030a-49cb-b926-5bfee09f6de4",
      "metadata": {
        "id": "5ce860b7-030a-49cb-b926-5bfee09f6de4"
      },
      "source": [
        "### Step 6: Loop through the Assistant run until status is 'completed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bd811a5c-982e-4623-943e-0265717ffa1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd811a5c-982e-4623-943e-0265717ffa1c",
        "outputId": "6cfd50c0-e5d3-45da-a744-46dc4a7a3a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"run_yhPlfNfrSXZ06TZxAMI2KVso\",\n",
            "    \"assistant_id\": \"asst_XrHEBSlOf5BFxVCkibWbvu56\",\n",
            "    \"cancelled_at\": null,\n",
            "    \"completed_at\": null,\n",
            "    \"created_at\": 1726655410,\n",
            "    \"expires_at\": 1726656010,\n",
            "    \"failed_at\": null,\n",
            "    \"incomplete_details\": null,\n",
            "    \"instructions\": \"Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n\",\n",
            "    \"last_error\": null,\n",
            "    \"max_completion_tokens\": null,\n",
            "    \"max_prompt_tokens\": null,\n",
            "    \"metadata\": {},\n",
            "    \"model\": \"gpt-4-1106-preview\",\n",
            "    \"object\": \"thread.run\",\n",
            "    \"parallel_tool_calls\": true,\n",
            "    \"required_action\": null,\n",
            "    \"response_format\": \"auto\",\n",
            "    \"started_at\": 1726655411,\n",
            "    \"status\": \"in_progress\",\n",
            "    \"thread_id\": \"thread_DEB9cE0RjOR3ExXXJNwZeEK8\",\n",
            "    \"tool_choice\": \"auto\",\n",
            "    \"tools\": [\n",
            "        {\n",
            "            \"type\": \"code_interpreter\"\n",
            "        }\n",
            "    ],\n",
            "    \"truncation_strategy\": {\n",
            "        \"type\": \"auto\",\n",
            "        \"last_messages\": null\n",
            "    },\n",
            "    \"usage\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"top_p\": 1.0,\n",
            "    \"tool_resources\": {}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "run_status = client.beta.threads.runs.retrieve(\n",
        "    thread_id = thread.id,\n",
        "    run_id = run.id\n",
        ")\n",
        "print(run_status.model_dump_json(indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b241e17-f6e6-4d7f-930b-e673163ccb8f",
      "metadata": {
        "id": "6b241e17-f6e6-4d7f-930b-e673163ccb8f"
      },
      "source": [
        "#### Poll until Assistant run is completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e11a1109-4918-42e5-94dc-366a8f30e2e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e11a1109-4918-42e5-94dc-366a8f30e2e9",
        "outputId": "2a7d9ef7-62e1-453f-c451-79b80095b97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(id='run_yhPlfNfrSXZ06TZxAMI2KVso', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=None, created_at=1726655410, expires_at=1726656010, failed_at=None, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655411, status='in_progress', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
            "Run(id='run_yhPlfNfrSXZ06TZxAMI2KVso', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=1726655419, created_at=1726655410, expires_at=None, failed_at=None, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655411, status='completed', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=91, prompt_tokens=396, total_tokens=487), temperature=1.0, top_p=1.0, tool_resources={})\n"
          ]
        }
      ],
      "source": [
        "def loop_until_completed1(clnt: object, thrd: object, run_obj: object) -> None:\n",
        "    \"\"\"\n",
        "    Poll the Assistant runtime until the run is completed or failed\n",
        "    \"\"\"\n",
        "    while run_obj.status not in [\"completed\", \"failed\", \"requires_action\"]:\n",
        "        run_obj = clnt.beta.threads.runs.retrieve(\n",
        "            thread_id = thrd.id,\n",
        "            run_id = run_obj.id)\n",
        "        time.sleep(10)\n",
        "        print(run_obj)\n",
        "loop_until_completed1(client, thread, run_status)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619f220c-1b7a-49e7-8afe-e8ff9bc2eef4",
      "metadata": {
        "id": "619f220c-1b7a-49e7-8afe-e8ff9bc2eef4"
      },
      "source": [
        "### Step 7: Retrieve the message returned by the assistance\n",
        "Only when the run is **completed** can you fetch the messages from the Thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "63ee0d97-492b-4d4b-a8be-c8a4ff95bcb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ee0d97-492b-4d4b-a8be-c8a4ff95bcb5",
        "outputId": "e3081813-9f2e-4a50-938a-69d2808eb21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('assistant:The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\), '\n",
            " 'Jules Dmatrix.')\n",
            "'user:I need to solve the equation `3x + 11 = 14`. Can you help me?'\n"
          ]
        }
      ],
      "source": [
        "print_thread_messages(client, thread)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z1iCaP7bqxDj",
      "metadata": {
        "id": "Z1iCaP7bqxDj"
      },
      "source": [
        "### **Repeat: Add message to assistant**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "zWcICpT3q6jJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWcICpT3q6jJ",
        "outputId": "ebbca89e-a9b9-4dde-cd59-d64c4c3a0eaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_wy3XB4x67QihzVmUwGqVbpom', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n    A cylindrical tank has a radius of 4 meters and a height of 10 meters.\\n\\nCalculate the volume of the tank.\\nIf water is being filled at a rate of 2 cubic meters per hour, how long will it take to fill the tank completely?\\nIf the tank is filled to three-quarters of its capacity, how much water (in liters) is in the tank?\\n    '), type='text')], created_at=1726655433, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"\"\"\n",
        "    A cylindrical tank has a radius of 4 meters and a height of 10 meters.\n",
        "\n",
        "Calculate the volume of the tank.\n",
        "If water is being filled at a rate of 2 cubic meters per hour, how long will it take to fill the tank completely?\n",
        "If the tank is filled to three-quarters of its capacity, how much water (in liters) is in the tank?\n",
        "    \"\"\",\n",
        ")\n",
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tzGJx2CVrACH",
      "metadata": {
        "id": "tzGJx2CVrACH"
      },
      "source": [
        "### **Repeat: Create another run for the Assistant for the second message**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "D2Uhr55GrK18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Uhr55GrK18",
        "outputId": "2a7501ad-ced7-4ab4-816e-e54f00cb910c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queued\n"
          ]
        }
      ],
      "source": [
        "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
        "run_status = client.beta.threads.runs.retrieve(\n",
        "    thread_id = thread.id,\n",
        "    run_id = run.id\n",
        ")\n",
        "\n",
        "print(run_status.status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "YvOyhvLjrNWf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvOyhvLjrNWf",
        "outputId": "501714d7-0fd6-4925-fe3c-c0d46a23bcba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(id='run_Y5Bd72CakXUiFJyLfUh5leoa', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=None, created_at=1726655433, expires_at=1726656033, failed_at=None, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655433, status='in_progress', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
            "Run(id='run_Y5Bd72CakXUiFJyLfUh5leoa', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=None, created_at=1726655433, expires_at=1726656033, failed_at=None, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655433, status='in_progress', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
            "Run(id='run_Y5Bd72CakXUiFJyLfUh5leoa', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=None, created_at=1726655433, expires_at=1726656033, failed_at=None, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655433, status='in_progress', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
            "Run(id='run_Y5Bd72CakXUiFJyLfUh5leoa', assistant_id='asst_XrHEBSlOf5BFxVCkibWbvu56', cancelled_at=None, completed_at=None, created_at=1726655433, expires_at=None, failed_at=1726655463, incomplete_details=None, instructions='Please address the user as Jules Dmatrix.\\n    Do not provide an answer to the question if the information was not retrieved from\\n    the knowledge base.\\n', last_error=LastError(code='rate_limit_exceeded', message='Rate limit reached for gpt-4-turbo-preview in organization org-72PztMKTHgAnHMUCoZQJxLDe on tokens per min (TPM): Limit 10000, Used 7898, Requested 4854. Please try again in 16.512s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.'), max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1726655433, status='failed', thread_id='thread_DEB9cE0RjOR3ExXXJNwZeEK8', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=238, prompt_tokens=1005, total_tokens=1243), temperature=1.0, top_p=1.0, tool_resources={})\n"
          ]
        }
      ],
      "source": [
        "loop_until_completed1(client, thread, run_status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "atpWajkLrP0z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atpWajkLrP0z",
        "outputId": "40c26451-45cc-45ba-81ca-654c988abc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('user:\\n'\n",
            " '    A cylindrical tank has a radius of 4 meters and a height of 10 meters.\\n'\n",
            " '\\n'\n",
            " 'Calculate the volume of the tank.\\n'\n",
            " 'If water is being filled at a rate of 2 cubic meters per hour, how long will '\n",
            " 'it take to fill the tank completely?\\n'\n",
            " 'If the tank is filled to three-quarters of its capacity, how much water (in '\n",
            " 'liters) is in the tank?\\n'\n",
            " '    ')\n",
            "('assistant:The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\), '\n",
            " 'Jules Dmatrix.')\n",
            "'user:I need to solve the equation `3x + 11 = 14`. Can you help me?'\n"
          ]
        }
      ],
      "source": [
        "print_thread_messages(client, thread)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
